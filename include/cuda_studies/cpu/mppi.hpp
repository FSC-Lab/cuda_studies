#ifndef CUDA_STUDIES_CPU_MPPI_HPP_
#define CUDA_STUDIES_CPU_MPPI_HPP_

#include <algorithm>
#include <random>
#include <vector>

#include "Eigen/Dense"

namespace fsc::cpu {

template <int NX>
struct RK4Result {
  double t;
  Eigen::Matrix<double, NX, 1> x;
};

template <typename Fcn, typename XDerived, typename UDerived,
          int NX = XDerived::SizeAtCompileTime>
RK4Result<NX> RK4Step(Fcn system, double t0,
                      const Eigen::MatrixBase<XDerived>& x0,
                      const Eigen::MatrixBase<UDerived>& u, double dt) {
  constexpr auto kOrder = 4;
  Eigen::Matrix<double, NX, kOrder> k;

  // First-order step
  k.col(0) = system(t0, x0, u);

  // Second-order step
  const double t_midway = t0 + 0.5 * dt;
  Eigen::Matrix<double, NX, 1> x_op;
  x_op = x0 + 0.5 * dt * k.col(0);
  k.col(1) = system(t_midway, x_op, u);

  // Third-order step
  x_op = x0 + 0.5 * dt * k.col(1);
  k.col(2) = system(t_midway, x_op, u);

  RK4Result<NX> res;
  // Fourth-order step
  res.t = t0 + dt;
  x_op = x0 + dt * k.col(2);
  k.col(3) = system(res.t, x_op, u);

  res.x = x0 + dt * k * Eigen::Vector4d(1.0, 2.0, 2.0, 1.0) / 6.0;
  return res;
}

/**
 * @brief
 *
 * @tparam NX Number of states
 * @tparam NU Number of inputs
 *
 * - High level inputs (c.f. references), potentially generated by a planner
 *
 * @tparam NV Number of outputs
 *
 * - Actual output by the `run` method
 * - Low level inputs (c.f. setpoints)
 * - Input to the system dynamics function
 *
 * @tparam NK Number of steps
 */
#ifdef ENABLE_TEMPLATE
template <int NX, int NU, int NV = NU, int NK = Eigen::Dynamic>
#endif
class MPPI {
 public:
#ifdef ENABLE_TEMPLATE
  enum { kNumStates = NX, kNumInputs = NU, kNumOutputs = NV, kNumSteps = NK };
#else
  enum {
    kNumStates = Eigen::Dynamic,
    kNumInputs = Eigen::Dynamic,
    kNumOutputs = Eigen::Dynamic,
    kNumSteps = Eigen::Dynamic
  };
#endif

  using State = Eigen::Matrix<double, kNumStates, 1>;
  using Input = Eigen::Matrix<double, kNumInputs, 1>;
  using Output = Eigen::Matrix<double, kNumOutputs, 1>;
  using StateTrajectory = Eigen::Matrix<double, kNumStates, kNumSteps + 1>;
  using InputTrajectory = Eigen::Matrix<double, kNumInputs, kNumSteps>;
  using OutputTrajectory = Eigen::Matrix<double, kNumOutputs, kNumSteps>;
  using InputCostMatrix = Eigen::Matrix<double, kNumInputs, kNumInputs>;

  // The system dynamics function dx/dt = f(t, x, u)
  using Dynamics = std::function<State(double, Eigen::Ref<const State>,
                                       Eigen::Ref<const Input>)>;

  struct ControlResult {
    Input input;
    Output output;
  };
  // The projection from the high level inputs/references to the low level
  // inputs/setpoints. This could be the flatness forward map.
  // Clamp functions go here
  using IOProjection = std::function<ControlResult(Eigen::Ref<const State>,
                                                   Eigen::Ref<const Input>)>;

  struct SearchResult {
    State state;
    Input input;
    double prog;
    double time;
    double dist;
  };
  // Searches for a nearest neighbor (subject to suitable norm) along state and
  // input trajectories
  using Searcher = std::function<SearchResult(double, Eigen::Ref<const State>,
                                              const StateTrajectory&,
                                              const InputTrajectory&)>;

  using RunningCost = std::function<double(
      double, double, Eigen::Ref<const State>, Eigen::Ref<const Input>,
      const Eigen::Ref<const Input>)>;
  using TerminalCost =
      std::function<double(double, double, Eigen::Ref<const State>, double)>;

  ControlResult run(double t, const State& x_t, const StateTrajectory& x_refs,
                    const InputTrajectory& u_refs) {
    const auto& closest_ref = searcher_(prev_progress_, x_t, x_refs, u_refs);
    const double optimal_progress = closest_ref.prog;
    const double optimal_time = closest_ref.time;

    prev_progress_ = optimal_progress;
    prev_time_ = t;
    Eigen::VectorXd cost(num_samples_);

    std::vector<InputTrajectory> epsilon(num_samples_);
    for (auto i = 0L; i < num_samples_; ++i) {
      State x_k = x_t;
      double t_k = optimal_time;
      double s_k = optimal_progress;
      Input prev_input = prev_optimal_input_;
      epsilon[i].resize(kNumSteps);
      for (auto k = 0L; k < kNumSteps; ++k) {
        const Input& nominal_input = u_refs.col(k);

        const Input noisy_input = nominal_input + sampleNoise();

        const auto& [actual_input, low_level_input] = proj_(x_k, noisy_input);

        // Run one RK4 step
        const auto& [t_next, x_next] =
            RK4Step(f_, t_k, x_k, low_level_input, timestep_);
        x_k = x_next;
        t_k = t_next;

        // Get (dz) the difference between the current noisy input and the
        // previous input, then swap in the current input
        const Input delta_input =
            actual_input - std::exchange(prev_input, actual_input);

        // Get (z_diff) the different between the nominal input and the noisy
        // and projected actual input
        const Input diff_input = actual_input - nominal_input;

        const auto p = lambda_ * diff_input.dot(inv_sigma_ * nominal_input);

        cost[i] += running_cost_(s_k, t_k, x_k, actual_input, delta_input) + p;
      }

      const auto progress = std::max(s_k - prev_progress_, 0.0);
      cost[i] += terminal_cost_(s_k, t_k, x_k, progress);
    }

    const auto w = computeWeights(cost);
    const auto w_epsilon = computePerturb(w, epsilon);
    const InputTrajectory optimal_inputs = u_refs + w_epsilon;
    return proj_(x_t, optimal_inputs.col(0));
  }

 private:
  Input sampleNoise() {
    return Input::NullaryExpr([this] { return dist_(rng_); });
  }

  [[nodiscard]] Eigen::VectorXd computeWeights(
      const Eigen::Ref<const Eigen::VectorXd>& cost) const {
    using Eigen::exp;

    const auto rho = cost.minCoeff();
    const auto eta = exp(-1.0 / lambda_ * (cost.array() - rho)).sum();

    return 1.0 / eta * exp(-1.0 / lambda_ * (cost.array() - rho)).matrix();
  }

  [[nodiscard]] InputTrajectory computePerturb(
      const Eigen::Ref<const Eigen::VectorXd>& w,
      const std::vector<InputTrajectory>& epsilon) const {
    InputTrajectory w_epsilon;
    for (auto k = 0L; k < kNumSteps; ++k) {
      for (auto i = 0L; i < num_samples_; ++i) {
        w_epsilon[k] += w[i] * epsilon[i][k];
      }
    }
    return w_epsilon;
  }

  Dynamics f_;
  IOProjection proj_;
  Searcher searcher_;

  double timestep_;
  double prev_progress_;
  double prev_time_;
  Input prev_optimal_input_;

  double lambda_;
  InputCostMatrix inv_sigma_{InputCostMatrix::Identity()};
  RunningCost running_cost_;
  TerminalCost terminal_cost_;

  Eigen::Index num_samples_;
  std::mt19937 rng_{std::random_device()()};
  std::normal_distribution<> dist_;
};
}  // namespace fsc::cpu

#endif  // CUDA_STUDIES_CPU_MPPI_HPP_
